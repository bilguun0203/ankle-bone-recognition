{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet import layers\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "from keras_retinanet.utils.anchors import make_shapes_callback\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = 'resnet50'\n",
    "# Annotation файлууд\n",
    "annotations_path = 'ankle_bones_dataset/annotations.csv'\n",
    "classes_path = 'ankle_bones_dataset/classes.csv'\n",
    "validations_path = 'ankle_bones_dataset/validations.csv'\n",
    "evaluation = True\n",
    "# Хэрэв сургалтаа үргэлжлүүлэх бол snapshot-ын утганд сүүлийн сургалтын файлыг зааж өгнө\n",
    "snapshot = None\n",
    "# Snapshot хадгалах эсэх, хадгалах хавтас\n",
    "snapshots = True\n",
    "snapshot_path = './snapshots'\n",
    "\n",
    "tensorboard_dir = './logs'\n",
    "\n",
    "weights = None\n",
    "imagenet_weights = True\n",
    "batch_size = 1\n",
    "image_min_side = 225\n",
    "image_max_side = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = models.backbone('resnet50')\n",
    "freeze_backbone = False\n",
    "common_args = {\n",
    "    'batch_size'       : batch_size,\n",
    "    'image_min_side'   : image_min_side,\n",
    "    'image_max_side'   : image_max_side,\n",
    "    'preprocess_image' : backbone_model.preprocess_image,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = CSVGenerator(annotations_path, classes_path, **common_args)\n",
    "if validations_path != '':\n",
    "    validation_generator = CSVGenerator(validations_path, classes_path, **common_args)\n",
    "else:\n",
    "    validation_generator = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if snapshot is not None:\n",
    "    print('Loading model, this may take a second...')\n",
    "    model = models.load_model(snapshot, backbone_name=backbone)\n",
    "    training_model = model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "else:\n",
    "    weights = weights\n",
    "    # default to imagenet if nothing else is specified\n",
    "    if weights is None and imagenet_weights:\n",
    "        weights = backbone_model.download_imagenet()\n",
    "\n",
    "    print('Creating model, this may take a second...')\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "    \n",
    "    model = backbone_model.retinanet(train_generator.num_classes(), modifier=modifier)\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=True)\n",
    "    training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "# print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# this lets the generator compute backbone layer shapes using the actual backbone model\n",
    "if 'vgg' in backbone or 'densenet' in backbone:\n",
    "    train_generator.compute_shapes = make_shapes_callback(model)\n",
    "    if validation_generator:\n",
    "        validation_generator.compute_shapes = train_generator.compute_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "tensorboard_callback = None\n",
    "\n",
    "if tensorboard_dir:\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "        log_dir                = tensorboard_dir,\n",
    "        histogram_freq         = 0,\n",
    "        batch_size             = batch_size,\n",
    "        write_graph            = True,\n",
    "        write_grads            = False,\n",
    "        write_images           = False,\n",
    "        embeddings_freq        = 0,\n",
    "        embeddings_layer_names = None,\n",
    "        embeddings_metadata    = None\n",
    "    )\n",
    "    callbacks.append(tensorboard_callback)\n",
    "\n",
    "if evaluation and validation_generator:\n",
    "    evaluation = Evaluate(validation_generator, tensorboard=tensorboard_callback)\n",
    "    evaluation = RedirectModel(evaluation, prediction_model)\n",
    "    callbacks.append(evaluation)\n",
    "\n",
    "# save the model\n",
    "if snapshots:\n",
    "    # ensure directory created first; otherwise h5py will error after epoch.\n",
    "    try:\n",
    "        os.makedirs(snapshot_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(snapshot_path):\n",
    "            raise\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(\n",
    "            snapshot_path,\n",
    "            '{backbone}_{dataset_type}_{{epoch:02d}}.h5'.format(backbone=backbone, dataset_type='csv')\n",
    "        ),\n",
    "        verbose=1,\n",
    "        # save_best_only=True,\n",
    "        # monitor=\"mAP\",\n",
    "        # mode='max'\n",
    "    )\n",
    "    checkpoint = RedirectModel(checkpoint, model)\n",
    "    callbacks.append(checkpoint)\n",
    "\n",
    "callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor  = 'loss',\n",
    "    factor   = 0.1,\n",
    "    patience = 2,\n",
    "    verbose  = 1,\n",
    "    mode     = 'auto',\n",
    "    epsilon  = 0.0001,\n",
    "    cooldown = 0,\n",
    "    min_lr   = 0\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "training_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
