{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шагайн дүрсийг таних модель сургах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шагайн хэлбэр буюу морь, тэмээ, хонь, ямаа гэсэн 4 төрлийн дүрсийг зурагнаас ялгаж таних моделийг үүсгэнэ.\n",
    "Моделийг үүсгэхдээ RetineNet ([https://arxiv.org/abs/1708.02002](https://arxiv.org/abs/1708.02002)) архитектурыг ашигласан.\n",
    "![](images/RetinaNet.png)\n",
    "RetinaNet нь ResNet архитектур дээр Feature Pyramid Network-ийг ашиглаж (a) олон төрлийн хэмжээтэй convolutional feature pyramid үүсгэдэг (b). Энэ RetinaNet-ийн сууринд хоёр дэд сүлжээ холбогддог. Нэг нь anchor box-ыг ангилдаг (c), нөгөө нь anchor box-ыг объектын хайрцаг болгодог (d). Энэ сүлжээ нь нэг үет илрүүлэгч (one-stage detector) ашигладаг ба хоёр үет илрүүлэгчийг (two-stage detector) (жишээ нь Faster-RCNN) бодвол илүү хурдан ажилладаг боловч нарийвчлал багатай. Харин loss тооцохдоо focal loss функцийг ашигласнаар нэг үет болон хоёр үет хоорондын нарийвчлалын ялгааг алга болгож, илүү хурдан бөгөөд нарийвчлал сайтай ажиллах боломжийг олгодог."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаардлагатай сангуудыг унших\n",
    "\n",
    "Ашигласан үндсэн сангууд:\n",
    "\n",
    "- `Tensorflow` - Keras-ийн backend\n",
    "\n",
    "- `Keras`\n",
    "\n",
    "- `Keras RetinaNet` - RetinaNet-ийг Keras дээр хэрэгжүүлсэн сан"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras_retinanet import models\n",
    "from keras_retinanet import layers\n",
    "from keras_retinanet import losses\n",
    "from keras_retinanet.models.retinanet import retinanet_bbox\n",
    "from keras_retinanet.preprocessing.csv_generator import CSVGenerator\n",
    "from keras_retinanet.utils.anchors import make_shapes_callback\n",
    "from keras_retinanet.utils.model import freeze as freeze_model\n",
    "from keras_retinanet.callbacks import RedirectModel\n",
    "from keras_retinanet.callbacks.eval import Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаардлагатай параметрууд\n",
    "\n",
    "- `annotations_path` - `images/hcsg_01.jpg,126,131,159,166,Camel` хэлбэрийн өгөгдөл агуулсан сургалтын файл\n",
    "- `classes_path` - ангилал, түүнд харгалзах id `horse,0`\n",
    "- `validations_path` - шалгах өгөгдлийн файл ба сургалтын өгөгдөлтэй адилхан бүтэцтэй файл\n",
    "- `evaluation` - шалгах эсэх\n",
    "- `snapshot` - үүссэн моделийг үргэлжлүүлж сурах бол замыг нь зааж өгнө\n",
    "- `snapshots` - давталт (epoch) болгонд моделийг хадгалах эсэх\n",
    "- `snapshot_path` - моделийг хадгалах байрлал"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = 'resnet50'\n",
    "# Annotation файлууд\n",
    "annotations_path = 'ankle_bones_dataset/annotations.csv'\n",
    "classes_path = 'ankle_bones_dataset/classes.csv'\n",
    "validations_path = 'ankle_bones_dataset/validations.csv'\n",
    "evaluation = True\n",
    "# Хэрэв сургалтаа үргэлжлүүлэх бол snapshot-ын утганд сүүлийн сургалтын файлыг зааж өгнө\n",
    "snapshot = None\n",
    "# Snapshot хадгалах эсэх, хадгалах хавтас\n",
    "snapshots = True\n",
    "snapshot_path = './snapshots'\n",
    "\n",
    "tensorboard_dir = './logs'\n",
    "\n",
    "weights = None\n",
    "imagenet_weights = True\n",
    "batch_size = 1\n",
    "image_min_side = 225\n",
    "image_max_side = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backbone модель ResNet50-р үүсгэх"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_model = models.backbone('resnet50')\n",
    "freeze_backbone = False\n",
    "common_args = {\n",
    "    'batch_size'       : batch_size,\n",
    "    'image_min_side'   : image_min_side,\n",
    "    'image_max_side'   : image_max_side,\n",
    "    'preprocess_image' : backbone_model.preprocess_image,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сургалт болон шалгалтын өгөгдлийн унших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сургалтын болон шалгах өгөгдлөө унших\n",
    "train_generator = CSVGenerator(annotations_path, classes_path, **common_args)\n",
    "if validations_path != '':\n",
    "    validation_generator = CSVGenerator(validations_path, classes_path, **common_args)\n",
    "else:\n",
    "    validation_generator = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель үүсгэх, унших\n",
    "\n",
    "Өмнө сургасан моделийг ашиглан үргэлжлүүлэн сургах бол тухайн моделийг уншина. Хэрэв шинээр сургах бол шинэ модель үүсгэнэ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-оо үүсгэх эсвэл өмнө нь үүссэн model-г унших\n",
    "if snapshot is not None:\n",
    "    print('Loading model, this may take a second...')\n",
    "    model = models.load_model(snapshot, backbone_name=backbone)\n",
    "    training_model = model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "else:\n",
    "    weights = weights\n",
    "    # default to imagenet if nothing else is specified\n",
    "    if weights is None and imagenet_weights:\n",
    "        weights = backbone_model.download_imagenet()\n",
    "\n",
    "    print('Creating model, this may take a second...')\n",
    "    modifier = freeze_model if freeze_backbone else None\n",
    "    \n",
    "    model = backbone_model.retinanet(train_generator.num_classes(), modifier=modifier)\n",
    "    if weights is not None:\n",
    "        model.load_weights(weights, by_name=True, skip_mismatch=True)\n",
    "    training_model = model\n",
    "\n",
    "    # make prediction model\n",
    "    prediction_model = retinanet_bbox(model=model)\n",
    "\n",
    "    # compile model\n",
    "    training_model.compile(\n",
    "        loss={\n",
    "            'regression'    : losses.smooth_l1(),\n",
    "            'classification': losses.focal()\n",
    "        },\n",
    "        optimizer=keras.optimizers.adam(lr=1e-5, clipnorm=0.001)\n",
    "    )\n",
    "\n",
    "# model-н тухай хураангуй\n",
    "print(model.summary())\n",
    "\n",
    "# this lets the generator compute backbone layer shapes using the actual backbone model\n",
    "if 'vgg' in backbone or 'densenet' in backbone:\n",
    "    train_generator.compute_shapes = make_shapes_callback(model)\n",
    "    if validation_generator:\n",
    "        validation_generator.compute_shapes = train_generator.compute_shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = []\n",
    "\n",
    "tensorboard_callback = None\n",
    "\n",
    "if tensorboard_dir:\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(\n",
    "        log_dir                = tensorboard_dir,\n",
    "        histogram_freq         = 0,\n",
    "        batch_size             = batch_size,\n",
    "        write_graph            = True,\n",
    "        write_grads            = False,\n",
    "        write_images           = False,\n",
    "        embeddings_freq        = 0,\n",
    "        embeddings_layer_names = None,\n",
    "        embeddings_metadata    = None\n",
    "    )\n",
    "    callbacks.append(tensorboard_callback)\n",
    "\n",
    "if evaluation and validation_generator:\n",
    "    evaluation = Evaluate(validation_generator, tensorboard=tensorboard_callback)\n",
    "    evaluation = RedirectModel(evaluation, prediction_model)\n",
    "    callbacks.append(evaluation)\n",
    "\n",
    "# model хадгалах\n",
    "if snapshots:\n",
    "    # хадгалах хавтсыг үүсгэх\n",
    "    try:\n",
    "        os.makedirs(snapshot_path)\n",
    "    except OSError:\n",
    "        if not os.path.isdir(snapshot_path):\n",
    "            raise\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        os.path.join(\n",
    "            snapshot_path,\n",
    "            '{backbone}_{dataset_type}_{{epoch:02d}}.h5'.format(backbone=backbone, dataset_type='csv')\n",
    "        ),\n",
    "        verbose=1,\n",
    "        # save_best_only=True,\n",
    "        # monitor=\"mAP\",\n",
    "        # mode='max'\n",
    "    )\n",
    "    checkpoint = RedirectModel(checkpoint, model)\n",
    "    callbacks.append(checkpoint)\n",
    "\n",
    "callbacks.append(keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor  = 'loss',\n",
    "    factor   = 0.1,\n",
    "    patience = 2,\n",
    "    verbose  = 1,\n",
    "    mode     = 'auto',\n",
    "    epsilon  = 0.0001,\n",
    "    cooldown = 0,\n",
    "    min_lr   = 0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сургалтыг эхлүүлэх"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сургалт эхлүүлэх\n",
    "training_model.fit_generator(\n",
    "    generator=train_generator,\n",
    "    steps_per_epoch=steps,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
